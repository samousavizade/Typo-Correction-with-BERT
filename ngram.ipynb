{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFLFdZ6nzm0I"
      },
      "source": [
        "# Loading train data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h5 dir=\"rtl\">\n",
        "در این بخش مدل زبانی N-gram را برای انجام این تسک استفاده می‌کنیم. ابتدا برای آموزش مدل، tokenization و normalization را روی متن اعمال می‌کنیم. \n",
        "<h5\\>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFbu_4MbSbuR",
        "outputId": "32ff6d82-9f58-4f48-ca3c-3cb6b94cc3a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: hazm in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
            "Requirement already satisfied: nltk==3.3 in /usr/local/lib/python3.7/dist-packages (from hazm) (3.3)\n",
            "Requirement already satisfied: libwapiti>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from hazm) (0.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: stanza in /usr/local/lib/python3.7/dist-packages (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stanza) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from stanza) (2.23.0)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from stanza) (1.11.0+cu113)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from stanza) (1.15.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (from stanza) (4.19.2)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (from stanza) (1.7.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from stanza) (3.17.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from stanza) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->stanza) (3.10.0.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2022.5.18.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers->stanza) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers->stanza) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers->stanza) (4.11.4)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers->stanza) (0.12.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->stanza) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->stanza) (3.7.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers->stanza) (0.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers->stanza) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers->stanza) (3.8.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.7)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.9.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.8.2)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.0.17)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy_stanza in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: stanza<1.5.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy_stanza) (1.4.0)\n",
            "Requirement already satisfied: spacy<4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy_stanza) (3.3.0)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy_stanza) (8.0.17)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy_stanza) (1.8.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy_stanza) (2.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy_stanza) (2.23.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy_stanza) (1.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy_stanza) (21.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy_stanza) (4.64.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy_stanza) (57.4.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy_stanza) (2.0.7)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy_stanza) (3.3.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy_stanza) (0.4.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy_stanza) (2.4.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy_stanza) (1.0.7)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy_stanza) (1.21.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy_stanza) (3.0.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy_stanza) (3.0.9)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy_stanza) (0.9.1)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy_stanza) (0.4.1)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy_stanza) (3.10.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy_stanza) (2.11.3)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.0.0->spacy_stanza) (0.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<4.0.0,>=3.0.0->spacy_stanza) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<4.0.0,>=3.0.0->spacy_stanza) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<4.0.0,>=3.0.0->spacy_stanza) (5.2.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy_stanza) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy_stanza) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy_stanza) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy_stanza) (3.0.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (from stanza<1.5.0,>=1.2.0->spacy_stanza) (4.19.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from stanza<1.5.0,>=1.2.0->spacy_stanza) (1.15.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from stanza<1.5.0,>=1.2.0->spacy_stanza) (3.17.3)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from stanza<1.5.0,>=1.2.0->spacy_stanza) (1.11.0+cu113)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (from stanza<1.5.0,>=1.2.0->spacy_stanza) (1.7.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<4.0.0,>=3.0.0->spacy_stanza) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<4.0.0,>=3.0.0->spacy_stanza) (2.0.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers->stanza<1.5.0,>=1.2.0->spacy_stanza) (4.11.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->stanza<1.5.0,>=1.2.0->spacy_stanza) (3.7.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->stanza<1.5.0,>=1.2.0->spacy_stanza) (2019.12.20)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers->stanza<1.5.0,>=1.2.0->spacy_stanza) (0.7.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers->stanza<1.5.0,>=1.2.0->spacy_stanza) (0.12.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers->stanza<1.5.0,>=1.2.0->spacy_stanza) (6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install hazm\n",
        "!pip install stanza\n",
        "!pip install spacy\n",
        "!pip install spacy_stanza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tG7J5v1Qud6",
        "outputId": "33ba5bbb-4d9c-4e34-9d4d-ce18736dd329"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qg0WT5B63Iie"
      },
      "outputs": [],
      "source": [
        "def pbar(x):\n",
        "  return tqdm(x, position=0, leave=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOl78t9mwfEw",
        "outputId": "6f57e8aa-a3d4-49a2-99e6-8ae5332d326d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1833371it [00:00, 2041135.67it/s]\n",
            "100%|██████████| 820000/820000 [00:00<00:00, 1480361.28it/s]\n"
          ]
        }
      ],
      "source": [
        "import codecs\n",
        "from tqdm import tqdm\n",
        "\n",
        "lines = [x for i, x in pbar(enumerate(codecs.open('/content/drive/MyDrive/Colab Notebooks/NLP/sports.txt','rU','utf-8').readlines())) if i<820000]\n",
        "paragraphs = []\n",
        "paragraph = ''\n",
        "for line in pbar(lines):\n",
        "    if line == '\\n':\n",
        "        paragraphs.append(paragraph)\n",
        "        paragraph = ''\n",
        "    else:\n",
        "        paragraph += line\n",
        "else:\n",
        "    paragraphs.append(paragraph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnlJ9KWRTuaD",
        "outputId": "18ee6fdf-2358-400e-d760-99d4828e39e0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 92195/92195 [01:20<00:00, 1144.51it/s]\n",
            "100%|██████████| 92195/92195 [00:07<00:00, 11815.32it/s]\n"
          ]
        }
      ],
      "source": [
        "from hazm import Normalizer\n",
        "from hazm import sent_tokenize\n",
        "from itertools import chain\n",
        "normalizer = Normalizer()\n",
        "paragraphs_normalized = [normalizer.normalize(paragraph) for paragraph in pbar(paragraphs)]\n",
        "sentences = list(chain(*[sent_tokenize(paragraph) for paragraph in pbar(paragraphs_normalized)]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrYNNtn7gR3Q"
      },
      "source": [
        "# Language Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h5 dir=\"rtl\">\n",
        "مدل به کار رفته همان مدل ارايه شده در کلاس است. صرفا تغییراتی روی آن اعمال شده. برای استخراج توکن ها به جای تابع split از nltk.tokenizer استفاده کردیم که مدل را بهبود داد. در مراحل میانی متغیرهای حجیمی را که در ادامه استفاده نمی شدند حذف کردیم تا در مصرف RAM صرفه‌جویی شود. تغیر مهم دیگر این بود که مدل اگر یک دنباله از کلمات را در مدل k-gram پیدا نکند، به دنبال  کلمات در مدل k-1-gram می‌گردد و ...  تابع best_candidate نیز در مواردی دچار خطا می‌شد که ایرادات آن نیز رفع شد.\n",
        "<h5\\>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nkby465EaxFy"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import nltk\n",
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "from itertools import product\n",
        "from os.path import exists\n",
        "import gc\n",
        "from hazm import word_tokenize\n",
        "\n",
        "class LanguageModel(object):\n",
        "    \"\"\"An n-gram language model trained on a given corpus.\n",
        "    \n",
        "    For a given n and given training corpus, constructs an n-gram language\n",
        "    model for the corpus by:\n",
        "    1. preprocessing the corpus (adding SOS/EOS/UNK tokens)\n",
        "    2. calculating (smoothed) probabilities for each n-gram\n",
        "    Also contains methods for calculating the perplexity of the model\n",
        "    against another corpus, and for generating sentences.\n",
        "    Args:\n",
        "        train_data (list of str): list of sentences comprising the training corpus.\n",
        "        n (int): the order of language model to build (i.e. 1 for unigram, 2 for bigram, etc.).\n",
        "        laplace (int): lambda multiplier to use for laplace smoothing (default 1 for add-1 smoothing).\n",
        "    \"\"\"\n",
        "\n",
        "    SOS = \"<s>\"\n",
        "    EOS = \"</s>\"\n",
        "    UNK = \"<UNK>\"\n",
        "    \n",
        "    def __init__(self, train_data, n, laplace=1, recalculate=True):\n",
        "        self.n = n\n",
        "        self.recalculate = recalculate\n",
        "        self.vocab = dict()\n",
        "        self.laplace = laplace\n",
        "        self.tokens = None\n",
        "        self.models = None\n",
        "\n",
        "        self.preprocess(train_data, n)\n",
        "        self._create_model()\n",
        "        self.masks  = list(reversed(list(product((0,1), repeat=n))))\n",
        "\n",
        "    def _smooth(self):\n",
        "        \"\"\"Apply Laplace smoothing to n-gram frequency distribution.\n",
        "        \n",
        "        Here, n_grams refers to the n-grams of the tokens in the training corpus,\n",
        "        while m_grams refers to the first (n-1) tokens of each n-gram.\n",
        "        Returns:\n",
        "            dict: Mapping of each n-gram (tuple of str) to its Laplace-smoothed \n",
        "            probability (float).\n",
        "        \"\"\"\n",
        "        pickle_name = f'models_{str(self.n)}.pickle'\n",
        "        if self.recalculate or not os.path.exists(pickle_name):\n",
        "            print('Recalculating model')\n",
        "            vocab_size = len(self.vocab)\n",
        "            n_vocabs = [None]*(self.n+1)\n",
        "            for i in range(2, self.n+1):\n",
        "                n_grams = nltk.ngrams(self.tokens, i)\n",
        "                n_vocab = nltk.FreqDist(n_grams)\n",
        "                n_vocabs[i] = n_vocab\n",
        "                del(n_grams)\n",
        "            gc.collect()\n",
        "            models = [None]*(self.n+1)\n",
        "            def smoothed_count(n_gram, n_count, n):\n",
        "                m_gram = n_gram[:-1]\n",
        "                m_count = n_vocabs[i][m_gram]\n",
        "                return (n_count + self.laplace) / (m_count + self.laplace * vocab_size)\n",
        "\n",
        "            num_tokens = len(self.tokens)\n",
        "            models[1] = { (unigram,): count / num_tokens for unigram, count in self.vocab.items() }\n",
        "            for i in range(2, self.n+1):\n",
        "                model = {\n",
        "                    n_gram: smoothed_count(n_gram, count, i) for n_gram, count in n_vocabs[i].items()\n",
        "                }\n",
        "                models[i] = model\n",
        "            self.models = models\n",
        "            pickle_out = open(pickle_name,\"wb\")\n",
        "            pickle.dump(models, pickle_out)\n",
        "            pickle_out.close()\n",
        "            del(n_vocabs)\n",
        "            gc.collect()\n",
        "        else:\n",
        "            print('Loading model')\n",
        "            pickle_in = open(pickle_name,\"rb\")\n",
        "            self.models = pickle.load(pickle_in)\n",
        "\n",
        "\n",
        "    def _create_model(self):\n",
        "        \"\"\"Create a probability distribution for the vocabulary of the training corpus.\n",
        "        \n",
        "        If building a unigram model, the probabilities are simple relative frequencies\n",
        "        of each token with the entire corpus.\n",
        "        Otherwise, the probabilities are Laplace-smoothed relative frequencies.\n",
        "        Returns:\n",
        "            A dict mapping each n-gram (tuple of str) to its probability (float).\n",
        "        \"\"\"\n",
        "        if self.n == 1:\n",
        "            num_tokens = len(self.tokens)\n",
        "            return { (unigram,): count / num_tokens for unigram, count in self.vocab.items() }\n",
        "        else:\n",
        "            return self._smooth()\n",
        "\n",
        "    def _convert_oov(self, ngram):\n",
        "        \"\"\"Convert, if necessary, a given n-gram to one which is known by the model.\n",
        "        Starting with the unmodified ngram, check each possible permutation of the n-gram\n",
        "        with each index of the n-gram containing either the original token or <UNK>. Stop\n",
        "        when the model contains an entry for that permutation.\n",
        "        This is achieved by creating a 'bitmask' for the n-gram tuple, and swapping out\n",
        "        each flagged token for <UNK>. Thus, in the worst case, this function checks 2^n\n",
        "        possible n-grams before returning.\n",
        "        Returns:\n",
        "            The n-gram with <UNK> tokens in certain positions such that the model\n",
        "            contains an entry for it.\n",
        "        \"\"\"\n",
        "        mask = lambda ngram, bitmask: tuple((token if flag == 1 else \"<UNK>\" for token,flag in zip(ngram, bitmask)))\n",
        "\n",
        "        ngram = (ngram,) if type(ngram) is str else ngram\n",
        "        for possible_known in [mask(ngram, bitmask) for bitmask in self.masks]:\n",
        "            if possible_known in self.model:\n",
        "                return possible_known\n",
        "\n",
        "    def perplexity(self, test_data):\n",
        "        \"\"\"Calculate the perplexity of the model against a given test corpus.\n",
        "        \n",
        "        Args:\n",
        "            test_data (list of str): sentences comprising the training corpus.\n",
        "        Returns:\n",
        "            The perplexity of the model as a float.\n",
        "        \n",
        "        \"\"\"\n",
        "        test_tokens = self.preprocess(test_data, self.n)\n",
        "        test_ngrams = nltk.ngrams(test_tokens, self.n)\n",
        "        N = len(test_tokens)\n",
        "\n",
        "        known_ngrams  = [self._convert_oov(ngram) for ngram in test_ngrams]\n",
        "        probabilities = [self.model[ngram] for ngram in known_ngrams]\n",
        "        \n",
        "        for x,y in zip(known_ngrams, probabilities):\n",
        "            print(x,y)\n",
        "        \n",
        "        return math.exp((-1/N) * sum(map(math.log, probabilities)))\n",
        "\n",
        "    def _best_candidate(self, prev, without=[], random=False):\n",
        "        \n",
        "        blacklist  = [LanguageModel.UNK] + without\n",
        "\n",
        "        if len(prev) < self.n-1:\n",
        "            prev = [LanguageModel.SOS]*(self.n-1 - len(prev)) + prev\n",
        "        elif len(prev) > self.n-1:\n",
        "            prev = prev[-(self.n-1):]\n",
        "        candidates = []\n",
        "        n = self.n\n",
        "        while len(candidates) == 0 and n > 0:\n",
        "            candidates = list(((ngram[-1],prob) for ngram,prob in self.models[n].items() if ngram[:-1]==tuple(prev[-(n-1):])))\n",
        "            n -= 1\n",
        "\n",
        "        if n == 0:\n",
        "            return [(\"\",0)]\n",
        "        return sorted(candidates, key=lambda x: -x[1])\n",
        "\n",
        "    def generate_sentence(self, min_len=12, max_len=24):\n",
        "        sent, prob = ([LanguageModel.SOS] * (max(1, self.n-1)), 1)\n",
        "        while sent[-1] != LanguageModel.EOS:\n",
        "            prev = [] if self.n == 1 else sent[-(self.n-1):]\n",
        "            blacklist = sent + ([LanguageModel.EOS,LanguageModel.SOS] if len(sent) < min_len else [])\n",
        "            next_token, next_prob = self._best_candidate(prev, without=blacklist)\n",
        "            sent.append(next_token)\n",
        "            prob *= next_prob\n",
        "\n",
        "            if len(sent) >= max_len:\n",
        "                sent.append(LanguageModel.EOS)\n",
        "\n",
        "        return (' '.join(sent[(self.n-1):-1]), -1/math.log(prob))\n",
        "    \n",
        "    \n",
        "\n",
        "    def add_sentence_tokens(self, sentences, n):\n",
        "        \"\"\"Wrap each sentence in SOS and EOS tokens.\n",
        "        For n >= 2, n-1 SOS tokens are added, otherwise only one is added.\n",
        "        Args:\n",
        "            sentences (list of str): the sentences to wrap.\n",
        "            n (int): order of the n-gram model which will use these sentences.\n",
        "        Returns:\n",
        "            List of sentences with SOS and EOS tokens wrapped around them.\n",
        "        \"\"\"\n",
        "        sos = ' '.join([LanguageModel.SOS] * (n-1)) if n > 1 else LanguageModel.SOS\n",
        "        return ['{} {} {}'.format(sos, s, LanguageModel.EOS) for s in sentences]\n",
        "\n",
        "    def replace_singletons(self, tokens):\n",
        "        \"\"\"Replace tokens which appear only once in the corpus with <UNK>.\n",
        "\n",
        "        Args:\n",
        "            tokens (list of str): the tokens comprising the corpus.\n",
        "        Returns:\n",
        "            The same list of tokens with each singleton replaced by <UNK>.\n",
        "\n",
        "        \"\"\"\n",
        "        if len(self.vocab) == 0:\n",
        "            self.vocab = nltk.FreqDist(tokens)\n",
        "        return [token if self.vocab[token] > 1 else LanguageModel.UNK for token in tokens]\n",
        "\n",
        "    def preprocess(self, sentences, n):\n",
        "        \"\"\"Add SOS/EOS/UNK tokens to given sentences and tokenize.\n",
        "        Args:\n",
        "            sentences (list of str): the sentences to preprocess.\n",
        "            n (int): order of the n-gram model which will use these sentences.\n",
        "        Returns:\n",
        "            The preprocessed sentences, tokenized by words.\n",
        "        \"\"\"\n",
        "        pickle_name = f'tokens_{str(self.n)}.pickle'\n",
        "\n",
        "        if self.recalculate or not os.path.exists(pickle_name):\n",
        "            print('Recalculating tokens')\n",
        "            sentences = self.add_sentence_tokens(sentences, n)\n",
        "            tokens =word_tokenize(' '.join(sentences))\n",
        "            self.tokens = self.replace_singletons(tokens)\n",
        "            pickle_out = open(pickle_name,\"wb\")\n",
        "            pickle.dump(tokens, pickle_out)\n",
        "            pickle_out.close()\n",
        "        else:\n",
        "            print('Loading tokens')\n",
        "            pickle_in = open(pickle_name,\"rb\")\n",
        "            self.tokens = pickle.load(pickle_in)\n",
        "\n",
        "        pickle_name = f'vocab_{str(self.n)}.pickle'\n",
        "        if self.recalculate or not exists(pickle_name):\n",
        "            print('Recalculating vocab')\n",
        "            self.vocab  = nltk.FreqDist(self.tokens)\n",
        "            pickle_out = open(pickle_name,\"wb\")\n",
        "            pickle.dump(self.vocab, pickle_out)\n",
        "            pickle_out.close()\n",
        "        else:\n",
        "            print('Loading vocab')\n",
        "            pickle_in = open(pickle_name,\"rb\")\n",
        "            self.vocab = pickle.load(pickle_in)\n",
        "          "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZlFPgeL-kd4",
        "outputId": "eb3873fc-d69a-401c-8be5-297dcd0bee57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recalculating tokens\n",
            "Recalculating vocab\n",
            "Recalculating model\n"
          ]
        }
      ],
      "source": [
        "language_model = LanguageModel(sentences, 3, 1, recalculate=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TlYqPTpV2KB"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h5 dir=\"rtl\">\n",
        "حال با استفاده از تابع best_candidate می‌خواهیم غلط های موجود را تصحیح کنیم. ابتدا متن ورودی را نرمال می‌کنیم. سپس به ازای هر توکن از متن، کلمات قبل از توکن را به ترتیب به تابع می‌دهیم تا بهترین حدس های مدل را خروجی دهد. سپس کلماتی که احتمال وقوع آن‌ها از یک مقدار آستانه کمتر باشد را حذف میکنیم. در مرحله‌ی بعدی کلماتی که نسبت فاصله‌ی ویرایشی آن‌ها با کلمه‌ی ورودی تقسیم بر طول کلمه‌ی ورودی از یک مقدار آستانه بیشتر باشد را حذف میکنیم. به زبان ساده برای کلمه‌های ۳و۴ حرفی اجازه‌ی یک فاصله‌ی نگارشی و برای کلمات ۴و۵و۶ و۷ حرفی اجازه‌ی دو فاصله‌ی نگارشی را می‌دهیم. در این بین اگر کلمه‌ی ورودی یکی از حروف اضافه باشد پردازشی روی آن رخ نمی دهد. همچنین اگر هیچ کلمه‌ای از فیلتر های فوق رد نشود نیز تغییری در کلمه‌ی ورودی داده نمی‌شود. در غیر این صورت کلمه‌ای که بیشنه‌ی معیار گفته شده را داشته باشد به عنوان بهترین کاندید خروجی می دهیم.  توجه کنید که به دلیل محدودیت RAM ما مدل را فقط بر روی بخشی از داده‌ی فایل sport.txt آموزش دادیم. لذا این مدل قادر به تصحیح غلط های املایی متن‌هایی با همین موضوع خواهد بود. طبیعتا با داده ی بیشتر عملکرد مدل بهتر می‌شود اما به دلیل محدودیت سخت‌افزاری قادر به آموزش مدل با داده ي بیشتر نبودیم.\n",
        "برای مثال جمله ی \"بازی برگذار شد.\" را در نظر بگیرید ابتدا  \"بازی برگذار\" به تابع best_candidate داده می‌شود که چون \"برگذار\" از نظر املایی غلط است و کلمه‌ی جایگزین \"برگزار\" معیارهای گفته شده را دارد پس این تصحیح صورت می‌گیرد. سپس \"بازی برگذار شد\" به تابع داده می‌شود که جایگزینی برای \"شد\" پیشنهاد نمی‌شود و همین طور بعد از دادن \"بازی برگذار شد.\" جایگزین بهتری برای \".\" پیدا نمی‌شود.\n",
        "<h5/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489,
          "referenced_widgets": [
            "33a2a11a7fd942fca51c0e5e7ec985cb",
            "494a0d1ff69a426ba572ad0ba52bbe53",
            "7b8a0a30d15c40eab82128fc5cfb0203",
            "4b9c0dff93ee4d8abaa98dd9faa5e2c4",
            "b9d0ef3b8aa84605821547c5d5ecae6c",
            "0d8d4300cd484c81962cc5ed65b40456",
            "8c5c91ff0c91403c9f80ca0d73a5d292",
            "6aa1582ee93547d8b0ba1da6da97ce9d",
            "22b2bf6d2fda472d8b5555eea4f9820f",
            "e7dae89ec2d6475eb841f056a4b1a005",
            "5e5ad3e643d24e42a8b4b605b0170026",
            "81aa85ebe18e4f50a791593cabf58c7c",
            "c4cda7076ea54fcc851365feef5f8bd6",
            "b5c3f04bf4734ab396adcb212d94f8b2",
            "2b3d8cbb88bc468db6cdc8bedce4c94b",
            "a3c0be2834b74a63b65123e2435ab595",
            "6e8bca48ae0f42d989a2ed33c65c30cb",
            "7a99883b740043588a19d5979e5d925a",
            "9d10c14408af49778d09452a6f6e2d33",
            "8c5fd0fa1cd24ef488f5234d445abaf0",
            "edcf78c553224cb1b7d3db2f718ad7c2",
            "a3bb563dd2c94718b5b0f4b6831cd013"
          ]
        },
        "id": "WVDvpGs62ewP",
        "outputId": "2c348a1f-faa4-4d11-94cb-54ca6886074e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-06-06 17:00:11 WARNING: Directory /root/stanza_corenlp already exists. Please install CoreNLP to a new directory.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "33a2a11a7fd942fca51c0e5e7ec985cb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.0.json:   0%|   …"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-06-06 17:00:11 INFO: Downloading default packages for language: fa (Persian)...\n",
            "2022-06-06 17:00:14 INFO: File exists: /root/stanza_resources/fa/default.zip\n",
            "2022-06-06 17:00:18 INFO: Finished downloading models and saved to /root/stanza_resources.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81aa85ebe18e4f50a791593cabf58c7c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.0.json:   0%|   …"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-06-06 17:00:19 INFO: Loading these models for language: fa (Persian):\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | perdt   |\n",
            "| mwt       | perdt   |\n",
            "| pos       | perdt   |\n",
            "| lemma     | perdt   |\n",
            "| depparse  | perdt   |\n",
            "| ner       | arman   |\n",
            "=======================\n",
            "\n",
            "2022-06-06 17:00:19 INFO: Use device: cpu\n",
            "2022-06-06 17:00:19 INFO: Loading: tokenize\n",
            "2022-06-06 17:00:19 INFO: Loading: mwt\n",
            "2022-06-06 17:00:19 INFO: Loading: pos\n",
            "2022-06-06 17:00:20 INFO: Loading: lemma\n",
            "2022-06-06 17:00:20 INFO: Loading: depparse\n",
            "2022-06-06 17:00:20 INFO: Loading: ner\n",
            "2022-06-06 17:00:21 INFO: Done loading processors!\n"
          ]
        }
      ],
      "source": [
        "from spacy.tokens.token import Token\n",
        "import editdistance\n",
        "import pandas as pd\n",
        "import stanza\n",
        "import spacy_stanza\n",
        "\n",
        "stanza.install_corenlp()\n",
        "stanza.download('fa')\n",
        "nlp = spacy_stanza.load_pipeline(\"fa\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8-DteZnjiuB",
        "outputId": "6d715ab1-e5e0-4137-ef17-743774c710e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'raw': 'دوشنبه', 'corrected': 'یکشنبه', 'span': [6, 12]}\n",
            "{'raw': 'مساف', 'corrected': 'مصاف', 'span': [16, 20]}\n",
            "{'raw': 'حندباز', 'corrected': 'هندبال', 'span': [4, 10]}\n",
            "{'raw': 'بانون', 'corrected': 'کانوی', 'span': [9, 14]}\n",
            "{'raw': 'تسمیم', 'corrected': 'تصمیم', 'span': [22, 27]}\n",
            "{'raw': 'بارصلونا', 'corrected': 'بارسلونا', 'span': [14, 22]}\n",
            "{'raw': 'بننا', 'corrected': 'بنا', 'span': [5, 9]}\n",
            "{'raw': 'اذربایجان', 'corrected': 'آذربایجان', 'span': [13, 22]}\n",
            "{'raw': 'زربه', 'corrected': 'ضربه', 'span': [7, 11]}\n",
            "{'raw': 'تصاوی', 'corrected': 'تساوی', 'span': [11, 16]}\n",
            "{'raw': 'فن', 'corrected': 'فنی', 'span': [6, 8]}\n",
            "{'raw': 'مخطلفی', 'corrected': 'مختلفی', 'span': [52, 58]}\n",
            "{'raw': 'برگذار', 'corrected': 'برگزار', 'span': [62, 68]}\n",
            "{'raw': 'هریفان', 'corrected': 'حریفان', 'span': [29, 35]}\n",
            "{'raw': 'مساف', 'corrected': 'مسافر', 'span': [39, 43]}\n",
            "{'raw': 'برگذار', 'corrected': 'برگزار', 'span': [25, 31]}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "texes = [\n",
        "\"امروز دوشنبه به مساف تیم ملی فوتبال رفت.\"\n",
        ", \"تیم حندباز ایتالیا قهرمان شد.\"\n",
        ", \"فدراسیون بانون با این تسمیم موافقت کرد.\"\n",
        ", \"پیوستن مسی به بارصلونا تاریخی بود.\"\n",
        ", \"محمد بننا به اذربایجان صفر کرد.\"\n",
        ", \"به توپ زربه زد.\"\n",
        ", \"بازی را واگذار کرد.\"\n",
        ", \"بازی را به تصاوی کشاند.\"\n",
        ", \"کمیته فن این فدراسیون در شرایطی بعد از المپیک جلسات مخطلفی را برگذار کرد.\"\n",
        ", \"مسابقه امروز برگزار می‌شود و هریفان به مساف هم می‌روند.\"\n",
        ", \"مسابقه‌ی فوتبال با تاخیر برگذار شد.\"\n",
        "]\n",
        "\n",
        "stop_words=['به','که','از','در','با','برای','تا','را']\n",
        "\n",
        "TRESHOLD = 0.4\n",
        "MIN_SCORE = 0.000001\n",
        "\n",
        "for text in texes:\n",
        "  k =  len(nlp(text))\n",
        "  text = normalizer.normalize(text)\n",
        "\n",
        "  for index in range(1,k-1):\n",
        "\n",
        "      doc = nlp(text)\n",
        "      current_token: Token = doc[index]\n",
        "      start_char_index = current_token.idx\n",
        "      end_char_index = start_char_index + len(current_token)\n",
        "      current_text = list(map(lambda x: x.text,doc[:index]))\n",
        "\n",
        "      if current_token.text in stop_words:\n",
        "        continue\n",
        "\n",
        "      predicts = language_model._best_candidate(current_text)\n",
        "      if predicts[0][0] is None:\n",
        "        continue\n",
        "\n",
        "      predicts = pd.DataFrame(predicts, columns = ['candidate', 'probability'])\n",
        "      predicts = predicts[predicts['probability']>MIN_SCORE]\n",
        "      predicts['edit_distance'] = predicts['candidate'].apply(lambda tk:editdistance.eval(current_token.text.strip(), tk.strip())/len(tk.strip()))\n",
        "      predicts = predicts[predicts['edit_distance']<=0.4]\n",
        "      predicts = predicts.sort_values(by=\"edit_distance\", ascending=True)\n",
        "\n",
        "      if predicts['candidate'].empty:\n",
        "        continue\n",
        "\n",
        "      selected_predict = predicts['candidate'].iloc[0]\n",
        "      if selected_predict.strip()!=current_token.text.strip():\n",
        "        output = {\"raw\":current_token.text,\"corrected\":selected_predict,\"span\":[start_char_index,end_char_index]}\n",
        "        print(output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0yEnW-L6YTk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "IBxnfqasgCoM"
      ],
      "name": "ngram.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0d8d4300cd484c81962cc5ed65b40456": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22b2bf6d2fda472d8b5555eea4f9820f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b3d8cbb88bc468db6cdc8bedce4c94b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edcf78c553224cb1b7d3db2f718ad7c2",
            "placeholder": "​",
            "style": "IPY_MODEL_a3bb563dd2c94718b5b0f4b6831cd013",
            "value": " 154k/? [00:00&lt;00:00, 3.51MB/s]"
          }
        },
        "33a2a11a7fd942fca51c0e5e7ec985cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_494a0d1ff69a426ba572ad0ba52bbe53",
              "IPY_MODEL_7b8a0a30d15c40eab82128fc5cfb0203",
              "IPY_MODEL_4b9c0dff93ee4d8abaa98dd9faa5e2c4"
            ],
            "layout": "IPY_MODEL_b9d0ef3b8aa84605821547c5d5ecae6c"
          }
        },
        "494a0d1ff69a426ba572ad0ba52bbe53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d8d4300cd484c81962cc5ed65b40456",
            "placeholder": "​",
            "style": "IPY_MODEL_8c5c91ff0c91403c9f80ca0d73a5d292",
            "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.0.json: "
          }
        },
        "4b9c0dff93ee4d8abaa98dd9faa5e2c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7dae89ec2d6475eb841f056a4b1a005",
            "placeholder": "​",
            "style": "IPY_MODEL_5e5ad3e643d24e42a8b4b605b0170026",
            "value": " 154k/? [00:00&lt;00:00, 3.76MB/s]"
          }
        },
        "5e5ad3e643d24e42a8b4b605b0170026": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6aa1582ee93547d8b0ba1da6da97ce9d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e8bca48ae0f42d989a2ed33c65c30cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a99883b740043588a19d5979e5d925a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b8a0a30d15c40eab82128fc5cfb0203": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6aa1582ee93547d8b0ba1da6da97ce9d",
            "max": 25998,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22b2bf6d2fda472d8b5555eea4f9820f",
            "value": 25998
          }
        },
        "81aa85ebe18e4f50a791593cabf58c7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4cda7076ea54fcc851365feef5f8bd6",
              "IPY_MODEL_b5c3f04bf4734ab396adcb212d94f8b2",
              "IPY_MODEL_2b3d8cbb88bc468db6cdc8bedce4c94b"
            ],
            "layout": "IPY_MODEL_a3c0be2834b74a63b65123e2435ab595"
          }
        },
        "8c5c91ff0c91403c9f80ca0d73a5d292": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c5fd0fa1cd24ef488f5234d445abaf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d10c14408af49778d09452a6f6e2d33": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3bb563dd2c94718b5b0f4b6831cd013": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3c0be2834b74a63b65123e2435ab595": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5c3f04bf4734ab396adcb212d94f8b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d10c14408af49778d09452a6f6e2d33",
            "max": 25998,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8c5fd0fa1cd24ef488f5234d445abaf0",
            "value": 25998
          }
        },
        "b9d0ef3b8aa84605821547c5d5ecae6c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4cda7076ea54fcc851365feef5f8bd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e8bca48ae0f42d989a2ed33c65c30cb",
            "placeholder": "​",
            "style": "IPY_MODEL_7a99883b740043588a19d5979e5d925a",
            "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.0.json: "
          }
        },
        "e7dae89ec2d6475eb841f056a4b1a005": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edcf78c553224cb1b7d3db2f718ad7c2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
